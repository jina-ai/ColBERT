model:
  name: "jinaai/jina-xlm-roberta-base-8k"
  checkpoint: ~
resources:
  accelerator: gpu
  gpus: [0]
  precision: 16-mixed
hyperparameters:
  loss: InfoNCE
  epochs: 1
  gradient_accumulation_steps: 1
  optimizer:
    name: AdamW
    options:
      lr: 3.0e-6
      betas:
        - 0.9
        - 0.999
      eps: 1.0e-8
      weight_decay: 0.01
      amsgrad: False
  scheduler:
    name: linear
    num_warmup_steps: 100
    num_training_steps: 2048
dataset:
  s3_bucket: "embedding-datasets"
  input_types:
    "*/triplets-multiple-negatives/*": MULTIPLE_NEGATIVES_WITHOUT_SCORES
  datasets: 
   - "en/triplets-multiple-negatives/msmarco-bge"
   - "en/triplets-multiple-negatives/nq-bge"
  max_shards: ~
  dialect: tsv
dataloader:
  batch_size: 16
  num_workers: 0
  num_negatives: 7
tokenizer:
  query_token: "[QueryMarker]"
  doc_token: "[DocMarker]"
  query_maxlen: 256
  doc_maxlen: 8192
interaction:
  similarity: cosine
  mask_punctuation: True
  attend_to_mask_tokens: False
callbacks:
  LearningRateMonitor:
    logging_interval: step
strategy:
  DeepSpeedStrategy:
    stage: 2
logger:
  WandbLogger:
    project: "jina-colbert"
profiler: ~
trainer_options:
  fast_dev_run: 64
  max_steps: ${hyperparameters.scheduler.num_training_steps}



  
