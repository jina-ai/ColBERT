model:
  name: jinaai/jina-xlm-roberta-base-8k-vol2-50k-steps-flash
  checkpoint: ~

resources:
  accelerator: gpu
  # If int: number of devices, if List[int]: device ids (assuming global view)
  gpus: [1]
  precision: 16-mixed

hyperparameters:
  loss: InfoNCE # or KLDiv
  optimizer:
    name: AdamW
    options:
      lr: 3.0e-6
      betas:
        - 0.9
        - 0.999
      eps: 1.0e-8
      weight_decay: 0.01
      amsgrad: False

    epochs: 1
    gradient_accumulation_steps: 1

  scheduler:
    name: cosine
    num_warmup_steps: 10
    num_training_steps: 20000

dataset:
  s3_bucket: "embedding-datasets"
  input_types:
    "*/triplets-multiple-negatives/*": MULTIPLE_NEGATIVES_WITHOUT_SCORES
  datasets:
    - "en/triplets-multiple-negatives/msmarco-bge"
    - "en/triplets-multiple-negatives/nq-bge"
  max_shards: ~
  dialect: tsv

dataloader:
  batch_size: 16
  num_workers: 0
  num_negatives: 7
tokenizer:
  query_token: "[QueryMarker]"
  doc_token: "[DocMarker]"
  query_maxlen: 128
  doc_maxlen: 256

interaction:
  similarity: cosine
  mask_punctuation: True
  attend_to_mask_tokens: False

logger:
  WandbLogger:
    project: jina-colbert

trainer_options:
  max_steps: ${hyperparameters.scheduler.num_training_steps}
  fast_dev_run: ~
  log_every_n_steps: 1

strategy:
  DeepSpeedStrategy:
    stage: 2

callbacks:
  LearningRateMonitor:
    logging_interval: step

  RichProgressBar:
    refresh_rate: 1

profiler: ~
  # PyTorchProfiler:
  #   dirpath: profiler_logs
  #   filename: profiler_results
  #   export_to_chrome: True
  
  





  
